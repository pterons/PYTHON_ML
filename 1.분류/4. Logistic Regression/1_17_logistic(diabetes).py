# -*- coding: utf-8 -*-
"""1-17.Logistic(diabetes).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10QbjoIxrxCLVy-So_9xdEoUEJHsqtefN
"""

# Logistic Regression으로 Breast Cancer 데이터를 학습한다.
# --------------------------------------------------------
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from sklearn.impute import SimpleImputer

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/Colab Notebooks'

# 데이터 파일을 읽어온다.
diabetes = pd.read_csv("data/diabetes.csv", index_col=False)
diabetes.head()

# null 값이 있는지 확인한다
diabetes.isnull().sum()

# feature 값이 0인 개수를 확인한다.
for feat in diabetes.columns:
    n = (diabetes[feat] == 0).sum()
    print('{}:{}개, 비율={:.3f}'.format(feat, n, n / len(diabetes)))
# diabetes.drop('Insulin', axis=1, inplace=True)

# feature 값이 0인 경우는 최빈값으로 대체한다. 단, Pregnancies와 Outcome은 제외한다.
imp = SimpleImputer(missing_values = 0, strategy = 'most_frequent')
cols = diabetes.columns[1:-1]
diabetes[cols] = imp.fit_transform(diabetes[cols])

diabetes.head(10)

# feature간 correlation을 확인한다
cor = diabetes.corr()
plt.figure(figsize=(8,8))
sns.heatmap(cor, annot=True)
plt.show()

# feature 값의 분포를 확인한다.
diabetes.hist(figsize=(10,8), bins=20)
plt.show()

# 로그변환
log_diab = diabetes.copy()

log_feats = ['BMI', 'DiabetesPedigreeFunction', 'Age']
log_diab[log_feats] = np.log1p(log_diab[log_feats])

# feature 값의 분포를 확인한다.
log_diab.hist(figsize=(10,8), bins=20)
plt.show()

# feature와 target을 분리한다.
target_data = log_diab['Outcome']
feature_data = log_diab.drop('Outcome', axis=1)

# Z-score normalization
z_cancer = StandardScaler().fit_transform(feature_data)

# Train 데이터 세트와 Test 데이터 세트를 구성한다
trainX, testX, trainY, testY = train_test_split(z_cancer, target_data, test_size = 0.2)

# Logistic Regression으로 Train 데이터 세트를 학습한다.
model = LogisticRegression()
model.fit(trainX, trainY)

# Test 세트의 Feature에 대한 class를 추정하고, 정확도를 계산한다
print("* 시험용 데이터로 측정한 정확도 = %.4f" % model.score(testX, testY))

