# -*- coding: utf-8 -*-
"""1-8.titanic(DTree).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mz1PMXlti7-QkARE8dbx_g9aR6XQEO_U
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Commented out IPython magic to ensure Python compatibility.
# 작업할 디렉토리로 이동
# %cd '/content/drive/My Drive/Colab Notebooks'

# 데이터를 읽어온다.
df = pd.read_csv('data/titanic_train.csv')
df.head(3)

# df.info()
df.isnull().sum()   # 결측치 개수 확인

# 결측치 처리
df['Age'].fillna(df['Age'].mean(), inplace = True)  # 평균으로 대체
df['Cabin'].fillna('N', inplace = True)
df['Embarked'].fillna('N', inplace = True)
# df.isnull().sum()   # 결측치 개수 확인

# 문자열 feature 값들의 분포 확인.
df['Pclass'].value_counts()
df['Sex'].value_counts()
df['Cabin'].value_counts()
df['Embarked'].value_counts()

# 'Cabin' feature는 첫 글자만 사용하기로 한다.
df['Cabin'] = df['Cabin'].str[:1]
df['Cabin'].value_counts()

# Name feature의 호칭 (title)을 발췌한다.
name = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
name.value_counts()

title = ['Mr', 'Miss', 'Mrs', 'Master']
df['Title'] = [x if x in title else 'Other' for x in name]

# Cabin, Sex, Embarked, Title 피처를 숫자형 카테고리로 변환한다.
le = {}
for feat in ['Cabin', 'Sex', 'Embarked', 'Title']:
    le[feat] = LabelEncoder()
    df[feat] = le[feat].fit_transform(df[feat])

# 불필요한 feature를 제거한다.
df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
df.head()

# 학습 데이터를 만든다.
target_data = df['Survived']
feature_data = df.drop('Survived', axis=1)
x_train, x_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.2)

# Decision Tree 학습
dt = DecisionTreeClassifier(max_depth = 5)
dt.fit(x_train, y_train)
dt_pred = dt.predict(x_test)

# 정확도를 측정한다
accuracy = accuracy_score(y_test, dt_pred)
print("Decision Tree accuracy = {0:.2f}".format(accuracy))

# feature별 중요도를 파악한다.
feat_impo = dt.feature_importances_
feat_name = feature_data.columns

plt.figure(figsize=(10, 4))
x_idx = np.arange(len(feat_name))
plt.barh(x_idx, feat_impo, align = 'center')
plt.yticks(x_idx, feat_name)
plt.xlabel('feature importance')
plt.ylabel('feature')
plt.show()

